import os
import asyncio
import itertools
import logging
from typing import List, Optional, Union, Literal, Any
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from openai import AsyncOpenAI

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),  # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        logging.FileHandler("matrix_test.log", encoding='utf-8')  # –í—ã–≤–æ–¥ –≤ —Ñ–∞–π–ª
    ]
)
logger = logging.getLogger("DeepSeekMatrix")

load_dotenv()

API_KEY = os.getenv("DEEPSEEK_API_KEY")
BASE_URL = "https://api.deepseek.com"

if not API_KEY:
    raise ValueError("DEEPSEEK_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")

client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
app = FastAPI(title="DeepSeek Matrix Tester")


# --- –ú–æ–¥–µ–ª–∏ ---

class Message(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    model: str = "deepseek-chat"
    messages: List[Message]
    temperature: Optional[float] = 1.0

    # –°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤
    response_format: List[Literal["text", "json_object", "json_schema"]] = Field(...)

    stop: Optional[Union[str, List[str]]] = None
    max_tokens: Optional[int] = None


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (—Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º) ---

async def perform_chat_request(
        key: str,
        model: str,
        messages: List[dict],
        temperature: float,
        fmt_str: str,
        stop_val: Any,
        token_val: Any
):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ –ª–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞.
    """
    try:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ response_format
        api_fmt = {"type": fmt_str}

        # –í–ê–ñ–ù–û: –î–ª—è "json_schema" DeepSeek —Ç—Ä–µ–±—É–µ—Ç –ø–æ–ª–µ 'json_schema' —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º.
        # –ó–¥–µ—Å—å –º—ã –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–ª—É—à–∫—É, —á—Ç–æ–±—ã –∑–∞–ø—Ä–æ—Å –Ω–µ —É–ø–∞–ª —Å 400 Bad Request,
        # –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±–µ—Ä–µ—Ç —ç—Ç–æ—Ç —Ç–∏–ø.
        if fmt_str == "json_schema":
            api_fmt["json_schema"] = {
                "name": "test_schema",
                "schema": {"type": "object", "properties": {"result": {"type": "string"}}}
            }

        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            response_format=api_fmt,
            stop=stop_val,
            max_tokens=token_val,
            stream=False
        )

        result_data = {
            "content": response.choices[0].message.content,
            "finish_reason": response.choices[0].finish_reason,
            "usage": response.usage.model_dump()
        }

        # --- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –£–°–ü–ï–•–ê ---
        logger.info(
            f"‚úÖ DONE: {key} | Reason: {result_data['finish_reason']} | Tokens: {result_data['usage']['total_tokens']}")

        return key, result_data

    except Exception as e:
        error_msg = str(e)

        # --- –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –û–®–ò–ë–ö–ò ---
        logger.error(f"‚ùå FAIL: {key} | Error: {error_msg}")

        return key, {"error": error_msg}


# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç ---

@app.post("/api/matrix-chat")
async def matrix_chat_proxy(request: ChatRequest):
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤ –æ–ø—Ü–∏–π (–µ—Å–ª–∏ None -> [None], –∏–Ω–∞—á–µ [None, value])
    stop_opts = [None, request.stop] if request.stop is not None else [None]
    token_opts = [None, request.max_tokens] if request.max_tokens is not None else [None]

    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ (–¥–µ–∫–∞—Ä—Ç–æ–≤–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ)
    combinations = itertools.product(request.response_format, stop_opts, token_opts)

    tasks = []

    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏
    for i, (fmt, stop_val, token_val) in enumerate(combinations, 1):
        key = (
            f"Scenario_{i}["
            f"fmt={fmt}, "
            f"stop={bool(stop_val)}, "
            f"max_tokens={bool(token_val)}"
            "]"
        )

        logger.info(f"üöÄ START: {key}")  # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—É—Å–∫

        tasks.append(
            perform_chat_request(
                key=key,
                model=request.model,
                messages=[m.model_dump() for m in request.messages],
                temperature=request.temperature,
                fmt_str=fmt,
                stop_val=stop_val,
                token_val=token_val
            )
        )

    if not tasks:
        raise HTTPException(status_code=400, detail="–ù–µ—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –∂–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    results = await asyncio.gather(*tasks)

    logger.info(f"üèÅ ALL DONE: Processed {len(results)} combinations.")

    # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å
    return dict(results)